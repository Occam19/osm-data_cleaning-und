{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# OPENSTREETMAP CLEANING PROJECT\n",
    "## By: Gurpal Sandhu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction - Todo: Split code into 2 parts. Cleaning & Importing, Queries.\n",
    "This project is designed to show my data cleaning and exploration skills using SQL and python. [I took open-source data from OpenStreetMaps of the Singapore and the area around it](https://www.openstreetmap.org/search?query=singapore#map=11/1.2905/103.8520) to scrub and analyze. \n",
    "\n",
    "The steps taken were:\n",
    "1. Check over the data. Done at first to find shape in python, later to find attribute data to answer questions with in SQL.\n",
    "2. Clean the data. Focused on cleaning addresses, in particular: street-end names, city names, and postcodes. Started by downloading and cleaning a small portion and then applying to main file. \n",
    "3. Convert the data into CSV from an XML formatted .OSM file. Then import into SQL db.\n",
    "4. Create questions about Singapore I would like to answer, and am able to answer using the data.\n",
    "5. Answer questions using SQL queries.\n",
    "6. Gave ideas for improvements to data, or alternate uses.\n",
    "\n",
    "## Data Cleaning\n",
    "\n",
    "The data downloaded from OpenStreetMaps is stored in an .osm file, size of 321 MB. An .osm file, as stated by the OpenStreetMaps wikipedia, uses the XML collapsible datastructure, along with a 'type:value' format to keep data tidy. I focused on cleaning the addresses of each node, since the address was what was input by hand by (fallible) human volunteers; in particular, the street-end names, city names, and postcodes.\n",
    "\n",
    "### Street-End Names\n",
    "\n",
    "A mapping was used to clean up the different end names. Since I had no awareness of typical Singaporean end names, I had to go back (after exploring with SQL) to include end-names like Lorong and Jalan alongside end-names like Street and Drive.\n",
    "\n",
    "    MAPPING = {\n",
    "        'Street':['str', 'st.', 'st'],\n",
    "        'Road':['rd', 'rd.'],\n",
    "        'Avenue':['ave', 'av', 'av.', 'ave.'],\n",
    "        'Jalan':['jl', 'jln', 'jl.'],\n",
    "        'Lane':['ln', 'ln.'],\n",
    "        'Drive':['dr', 'dr.'],\n",
    "        'Lorong':['lr', 'lr.'],\n",
    "        'Square':['sq', 'sq.']\n",
    "    }\n",
    "### Postcodes\n",
    "\n",
    "Postcodes in Singapore are a 6 number string with the first two numbers the general area, and the last four the exact location. Some online research showed me that the 81 postcode area is the newest postal sector, and in my SQL queries, I noticed that it had many of the bad post codes. The steps used to clean the codes were:\n",
    "1. Remove all non-numbers. Done using regex (regular expressions module in python).\n",
    "\n",
    "        newstring = re.sub('[^0-9]','', string)\n",
    "\n",
    "2. Add 0 in front of 9---- 5 length numbers (there are no codes that start with 9 in Singapore)\n",
    "3. Add 0 to end of numbers with 2 00s on end that are 5 length numbers (these are estimations)\n",
    "4. Rest are removed, replaced with ''.\n",
    "\n",
    "### City Names\n",
    "\n",
    "Oftentimes, extra information would be put here instead of or alongside the cityname.\n",
    "First, any city names with any numbers in the string AND with fewer letters than 3 were automatically deleted. Regex was used here.\n",
    "Then, a mapping was used to fix the rest of the city names. The majority of names are the 5 big ones:\n",
    "\n",
    "    CITYNAMES = {\"singap\" : \"Singapore\",           # singap to encompass all spellings of singap - ur, or, ore, our\n",
    "                 \"johor bahru\" : \"Johor Bahru\",    # written in order of size to choose most likely city for multiple named city\n",
    "                 \"pasir gudang\" : \"Pasir Gudang\", \n",
    "                 \"batam\" : \"Batam\", \n",
    "                 \"skudai\" : \"Skudai\"}\n",
    "There were many variations in the data for city names(ie. Singapore/singapur). As a result, if it had 'singap', 'bahru', 'pasir', 'batam', 'skudai' anywhere in the string, it was changed to align. Finally, the first letter was changed to uppercase - for any city name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#type = 'addr', key = 'street', 'city', 'postcode', 'housenumber'\n",
    "# - Clean addresses here, using recompile, mainly postal codes, city names, street end names\n",
    "\n",
    "#NOTE: filtered renamed cities and estimated postal codes out of print statements, \n",
    "#they were the majority of the errors and took up the majority of the print statements\n",
    "\n",
    "import re\n",
    "\n",
    "# Seems that 81 is the newest postal sector, has many of the bad postcodes - first 2 digits are sector, last two are \n",
    "# If the last two digits of a postcode are '00', it indicates a rough guess of a post code\n",
    "# how to fix post codes\n",
    "#remove all non-numbers from postcodes\n",
    "#add 0 in front of 9---- 5 length numbers (there are no codes that start with 9 in singapore)\n",
    "#add 0 to end of numbers with 2 00s on end that are 5 length numbers (these are estimations)\n",
    "#rest should be removed - give examples of the deleted ones\n",
    "\n",
    "def audit_postcode (string):\n",
    "    #remove all non-numbers\n",
    "    newstring = re.sub('[^0-9]','', string)\n",
    "    if len(newstring) == 6:\n",
    "        return newstring\n",
    "    #add 0 in front of 9---- 5 length numbers (there are no codes that start with 9 in singapore, miust be 6 numbers)\n",
    "    #add 0 to end of numbers with 2 00s on end that are 5 length numbers (these are estimates)\n",
    "    if len(newstring) == 5:\n",
    "        if newstring[0] == '9':\n",
    "            newstring2 = '0' + newstring\n",
    "            print 'ERROR POSTCODE: ' + newstring + ' -> ' + newstring2\n",
    "            return newstring2\n",
    "        if newstring[-2:] == '00':\n",
    "            newstring3 = newstring + '0'\n",
    "            print 'ERROR POSTCODE: ' + newstring + ' -> ' + newstring3\n",
    "            return newstring3\n",
    "    #rest should be removed - give examples of the deleted ones\n",
    "    #should we delete all info for the node? nahh\n",
    "    #we should just delete that line address\n",
    "    #print 'ERROR POSTCODE: ' + string + ' -> BADSTRING'\n",
    "    return ''\n",
    "    \n",
    "#city names - Singapore, Johor Bahru, Pasir Gudang, Batam, Skudai\n",
    "#Different Names for main cities - translate into 5 main cities\n",
    "#check if has 'johor' / 'batam' / 'skudai' / 'singapore' in string - rename to main city using regular expressions\n",
    "# The problem is writing house#, street name or post code for this part - delete those entries (any that have #s or \n",
    "# Make sure to give examples of deleted entries\n",
    "# There are some that are islands off the coast or non-Johor Malaysia\n",
    "CITYNAMES = {\"singap\" : \"Singapore\",           # singap to encompass all spellings of singap - ur, or, ore, our\n",
    "             \"johor\" : \"Johor Bahru\",    # written in order of size to choose most likely city for multiple named city\n",
    "             \"pasir\" : \"Pasir Gudang\", \n",
    "             \"batam\" : \"Batam\", \n",
    "             \"skudai\" : \"Skudai\"}\n",
    "\n",
    "def audit_cityname (string, citynames = CITYNAMES):\n",
    "    string = string.lower()\n",
    "    #check if has 'johor' / 'batam' / 'skudai' / 'singapore' /'pasir' in string - rename to main city using mapping\n",
    "    for name in citynames.keys():\n",
    "        if name in string:\n",
    "            return citynames[name]\n",
    "    #REMOVE any entries that have numberss in them AND has less than 3 letters in string - show why with list of bad\n",
    "    if re.search('^#[\\d]{2}-[\\d]{2}', string):\n",
    "            print 'ERROR CITY: ' + string + ' -> ADDR:UNIT'\n",
    "            return 'unit: ' + string \n",
    "    if bool(re.search(r'\\d', string)) and bool(sum(c.isalpha() for c in string) < 2):\n",
    "        print 'ERROR CITY: ' + string + ' -> BADSTRING'\n",
    "        return 'BADSTRING'\n",
    "    return string.title()  # capitalize any other city names\n",
    "    \n",
    "#Street Names - Singapore has many different kinds, hard to fix any\n",
    "#Make street names consistent with Rd. -> Road, Ave -> Avenue [Search the entire string for inconcistensy]\n",
    "#Delete anything after designator numbers in string?\n",
    "#Change any jl, jln, jl. to Jalan (Means way in Malay)\n",
    "#Recheck data, after each audit -> mayhap delete any string data after 1st comma OR semicolon (incorrect fillout of form) IF it has one of the street endings\n",
    "\n",
    "MAPPING = {\n",
    "    'Street':['str', 'st.', 'st'],\n",
    "    'Road':['rd', 'rd.'],\n",
    "    'Avenue':['ave', 'av', 'av.', 'ave.'],\n",
    "    'Jalan':['jl', 'jln', 'jl.'],\n",
    "    'Lane':['ln', 'ln.'],\n",
    "    'Drive':['dr', 'dr.'],\n",
    "    'Lorong':['lr', 'lr.'],\n",
    "    'Square':['sq', 'sq.']\n",
    "}\n",
    "\n",
    "#split string on space AND '.', for each word -> strip spaces:\n",
    "#convert rd., rd -> Road, jl, jln, jl. -> Jalan, st, st. str -> Street, blvd, dr, ct, pl, ln,\n",
    "#batu(stone), lorong(hallway), \n",
    "\n",
    "#audit_streetname helper function, compares each word to mapping dictionary\n",
    "def check_word_for_streettype (string, dictionary):\n",
    "    for streettype, mapping in dictionary.items():\n",
    "        for abbreviation in mapping:\n",
    "            if string == abbreviation:\n",
    "                print 'ERROR STREETNAME: ' + string + ' -> ' + streettype\n",
    "                return streettype\n",
    "    return string\n",
    "\n",
    "def audit_streetname (string):\n",
    "    audited_addr = ''\n",
    "    temp_string = string.strip().lower().split()\n",
    "    for part in temp_string:\n",
    "        audited_part = check_word_for_streettype(part, MAPPING)\n",
    "        audited_addr += audited_part.title() + ' '\n",
    "    return audited_addr[:-1]\n",
    "\n",
    "def audit_value(value, address_part):\n",
    "    if address_part == 'postcode':\n",
    "        return audit_postcode(value)\n",
    "    elif address_part == 'city':\n",
    "        return audit_cityname(value)\n",
    "    elif address_part == 'street':\n",
    "        return audit_streetname(value)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Importing / SQL Overview\n",
    "\n",
    "The map data was extracted from an XML format, and changed from XML to python's dict structure. Then, the values were audited and cleaned as shown above. The data was separated into 5 csv files, and finally imported into SQL under the same headers.  I also tried importing directly from the command line, but the encoding was finicky. The CSV / SQL column names are below.\n",
    "\n",
    "    NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "    NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "    WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "    WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "    WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "### File Sizes\n",
    "Singapore.osm - 321 MB\n",
    "nodes, nodes_tags, ways, ways_nodes, ways_tags . csv - 201 MB\n",
    "SingaporeMap.db - 182 MB\n",
    "\n",
    "### Node and Ways Count\n",
    "\n",
    "    sqlite> SELECT COUNT(*) FROM nodes;\n",
    "\n",
    "    Nodes : 1482437\n",
    "\n",
    "    sqlite> SELECT COUNT(*) FROM ways;\n",
    "    \n",
    "    Ways : 233033\n",
    "### Unique Contributor Data\n",
    "\n",
    "    sqlite > SELECT COUNT(DISTINCT(tags.uid))\n",
    "             FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) AS tags;\n",
    "             \n",
    "    Total Contributor Count : 2057\n",
    "\n",
    "    sqlite > SELECT tags.user, COUNT(*) as num\n",
    "             FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) AS tags\n",
    "             GROUP BY tags.user ORDER BY num DESC\n",
    "             LIMIT 5;\n",
    "             \n",
    "    Top 5 Contributors:\n",
    "        JaLooNz, 395146\n",
    "        berjaya, 117636\n",
    "        rene78, 78269\n",
    "        cboothroyd, 73129\n",
    "        lmum, 44070"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSSIBLE : sungai rengit\n",
      "POSSIBLE : sekupang\n",
      "POSSIBLE : masai\n",
      "POSSIBLE : masai\n",
      "POSSIBLE : masai\n",
      "POSSIBLE : masai\n",
      "POSSIBLE : masai\n",
      "POSSIBLE : masai\n",
      "POSSIBLE : bintan\n",
      "POSSIBLE : holland village\n",
      "POSSIBLE : ulu tiram\n",
      "POSSIBLE : ulu tiram\n",
      "POSSIBLE : ulu tiram\n",
      "POSSIBLE : ulu tiram\n",
      "POSSIBLE : ulu tiram\n",
      "POSSIBLE : ulu tiram\n",
      "POSSIBLE : ulu tiram\n",
      "POSSIBLE : ulu tiram\n",
      "POSSIBLE : karimun\n",
      "POSSIBLE : gelang patah\n",
      "POSSIBLE : punggol\n",
      "POSSIBLE : changi village\n",
      "ERROR CITY: #01-58/60 -> ADDR:UNIT\n",
      "ERROR CITY: #01-50 -> ADDR:UNIT\n",
      "ERROR CITY: #01-38/40/42 -> ADDR:UNIT\n",
      "ERROR CITY: #01-46 -> ADDR:UNIT\n",
      "ERROR CITY: #01-33 -> ADDR:UNIT\n",
      "ERROR CITY: #01-05 -> ADDR:UNIT\n",
      "ERROR CITY: #01-06 -> ADDR:UNIT\n",
      "ERROR CITY: #01-62 -> ADDR:UNIT\n",
      "ERROR CITY: #01-44 -> ADDR:UNIT\n",
      "POSSIBLE : sembawang\n",
      "POSSIBLE : taman bukit dahlia\n",
      "POSSIBLE : taman perling\n",
      "POSSIBLE : taman nusantara\n",
      "POSSIBLE : sembawang\n",
      "POSSIBLE : sembawang\n",
      "POSSIBLE : ang mo kio\n",
      "POSSIBLE : pulai johor\n",
      "POSSIBLE : 82000\n",
      "ERROR CITY: 82000 -> BADSTRING\n",
      "POSSIBLE : sembawang\n",
      "POSSIBLE : woodlands spectrum ii\n",
      "POSSIBLE : taman century\n",
      "POSSIBLE : iskandar puteri\n",
      "POSSIBLE : iskandar puteri\n",
      "POSSIBLE : iskandar puteri\n",
      "POSSIBLE : iskandar puteri\n",
      "POSSIBLE : iskandar puteri\n",
      "POSSIBLE : iskandar puteri\n",
      "POSSIBLE : iskandar puteri\n",
      "POSSIBLE : tanjung puteri\n",
      "POSSIBLE : iskandar puteri\n",
      "POSSIBLE : kulai\n",
      "POSSIBLE : kulai\n",
      "POSSIBLE : masai\n",
      "POSSIBLE : masai\n",
      "POSSIBLE : masai\n",
      "POSSIBLE : masai\n",
      "POSSIBLE : masai\n",
      "POSSIBLE : masai\n",
      "POSSIBLE : masai\n",
      "POSSIBLE : danga bay\n",
      "POSSIBLE : kulai\n",
      "POSSIBLE : kota tinggi\n",
      "POSSIBLE : taman johor jaya\n",
      "POSSIBLE : nusajaya\n",
      "POSSIBLE : nusajaya\n",
      "POSSIBLE : nusajaya\n",
      "POSSIBLE : bandar baru permas jaya\n",
      "POSSIBLE : ulu tiram\n",
      "POSSIBLE : kulai\n",
      "POSSIBLE : medini\n",
      "POSSIBLE : gelang patah\n",
      "POSSIBLE : 140\n",
      "ERROR CITY: 140 -> BADSTRING\n",
      "POSSIBLE : johor bharu\n",
      "POSSIBLE : masai\n",
      "POSSIBLE : ulu tiram\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import csv\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "OSM_PATH = \"singapore.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "def extract_tag_info(element, problem_chars=PROBLEMCHARS):\n",
    "    tags = []   # Handle secondary tags the same way for both node and way elements\n",
    "    for tag in element.findall('tag'):\n",
    "        tag_info = {}\n",
    "        tag_info['id'] = element.attrib['id']\n",
    "        tag_info['value'] = tag.attrib['v']\n",
    "        if problem_chars.match(tag.attrib['k']):\n",
    "            continue\n",
    "        elif ':' not in tag.attrib['k']:\n",
    "            tag_info['key'] = tag.attrib['k']\n",
    "            tag_info['type'] = 'regular'\n",
    "        else:\n",
    "            (tag_info['type'],c,tag_info['key']) = tag.attrib['k'].partition(':')\n",
    "            if tag_info['type'] == 'addr':\n",
    "                tag_info['value'] = audit_value(tag_info['value'], tag_info['key'])\n",
    "                if tag_info['value'] == 'BADSTRING':\n",
    "                    continue\n",
    "                if tag_info['value'] == 'addr:unit':\n",
    "                    tag_info['key'] = 'unit'\n",
    "                    tag_info['value'] = tag.attrib['v']\n",
    "        tags.append(tag_info)\n",
    "    return tags\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    \n",
    "    if element.tag == 'node':\n",
    "        for key in node_attr_fields:\n",
    "            node_attribs[key] = element.attrib[key]\n",
    "        tags = extract_tag_info(element)\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        for key in way_attr_fields:\n",
    "            way_attribs[key] = element.attrib[key]\n",
    "        tags = extract_tag_info(element)\n",
    "        for position, nd in enumerate(element.findall('nd')):\n",
    "            way_node_info = {}\n",
    "            way_node_info['id'] = element.attrib['id']\n",
    "            way_node_info['node_id'] = nd.attrib['ref']\n",
    "            way_node_info['position'] = position\n",
    "            way_nodes.append(way_node_info)\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "# Helper Functions\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# Main Function\n",
    "def process_map(file_in):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "process_map(OSM_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "##function to import any csv file to sqlite3 db, columns_vartype is an OrderedDict with line data\n",
    "def import_csv(tablename, columns_vartype, filename):\n",
    "\n",
    "    cursor.execute('''DROP TABLE IF EXISTS {}'''.format(tablename))\n",
    "    connection.commit()\n",
    "\n",
    "    # creates strings for CREATE TABLE and INSERT INTO queries of multiple variable amounts\n",
    "    query1 = ('''CREATE TABLE %s (''' % tablename)\n",
    "    query2 = (\"INSERT INTO %s(\" % tablename)\n",
    "    subquery = \"(\"\n",
    "    for val in columns_vartype.keys():\n",
    "        query1 += ('''%s %s NOT NULL''' % (val, columns_vartype[val]))\n",
    "        if val == columns_vartype.keys()[-1]:\n",
    "            query1 += (\");\")\n",
    "            query2 += (\"%s) VALUES \" % val)\n",
    "            subquery += \"?);\"\n",
    "        else:\n",
    "            query1 += (\", \")\n",
    "            query2 += (\"%s, \" % val)\n",
    "            subquery += \"?, \"\n",
    "    query2 += subquery        \n",
    "    \n",
    "    cursor.execute(query1)\n",
    "    connection.commit()\n",
    "\n",
    "    \n",
    "    with open(filename) as fin:\n",
    "        data = csv.DictReader(fin)\n",
    "        create_db = []\n",
    "        for row in data:\n",
    "            temp_db = []\n",
    "            for value in columns_vartype.keys():\n",
    "                temp_db.append(row[value].decode(\"utf-8\"))\n",
    "            create_db.append(temp_db)\n",
    "              \n",
    "    cursor.executemany(query2, create_db)\n",
    "    connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "## Import data into SQLITE database\n",
    "## I tried to import directly from command line, but the encoding was finicky. \n",
    "import csv\n",
    "import sqlite3\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "sqlite3_filename = 'SingaporeMap2.db'\n",
    "connection = sqlite3.connect(sqlite3_filename)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "Nodes_Dictionary = OrderedDict([('id', 'INTEGER'), ('lat', 'REAL'), ('lon', 'REAL'), ('user', 'TEXT'), \n",
    "                                ('uid', 'INTEGER'), ('version', 'INTEGER'), ('changeset', 'INTEGER'), ('timestamp', 'TEXT')])\n",
    "Nodes_Tags_Dictionary = OrderedDict([('id', 'INTEGER'), ('key', 'TEXT'), ('value', 'TEXT'), ('type', 'TEXT')])\n",
    "Ways_Dictionary = OrderedDict([('id', 'INTEGER'), ('user', 'TEXT'), ('uid', 'INTEGER'), ('version', 'INTEGER'), \n",
    "                               ('changeset', 'INTEGER'), ('timestamp', 'TEXT')])\n",
    "Ways_Nodes_Dictionary = OrderedDict([('id', 'INTEGER'), ('node_id', 'INTEGER'), ('position', 'INTEGER')])\n",
    "Ways_Tags_Dictionary = OrderedDict([('id', 'INTEGER'), ('key', 'TEXT'), ('value', 'TEXT'), ('type', 'TEXT')])\n",
    "\n",
    "import_csv('Nodes_Tags', Nodes_Tags_Dictionary, 'nodes_tags.csv')\n",
    "import_csv('Nodes', Nodes_Dictionary, 'nodes.csv')\n",
    "import_csv('Ways', Ways_Dictionary, 'ways.csv')\n",
    "import_csv('Ways_Nodes', Ways_Nodes_Dictionary, 'ways_nodes.csv')\n",
    "import_csv('Ways_Tags', Ways_Tags_Dictionary, 'ways_tags.csv')\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answering Questions about Singapore\n",
    "### Major Streets\n",
    "I wanted to know what the major streets of Singapore were. I looked for streets with the most OSM objects connected to it.\n",
    "        \n",
    "    sqlite > SELECT tags.value, COUNT(*) \n",
    "             FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) AS tags \n",
    "             WHERE type = 'addr' and key = 'street' \n",
    "             GROUP BY tags.value ORDER BY COUNT(*) DESC LIMIT 10;\n",
    "      \n",
    "    Joo Chiat Road, 347\n",
    "    Geylang Road, 261\n",
    "    Serangoon Road, 246\n",
    "    Jalan Senang, 234\n",
    "    South Bridge Road, 197\n",
    "    Jalan Besar, 192\n",
    "    North Bridge Road, 188\n",
    "    Tanjong Pagar Road, 181\n",
    "    Arab Street, 168\n",
    "    Westwood Crescent, 165\n",
    "### Tea vs Coffee Preference\n",
    "Another question I had was whether a highly developed Eastern city like Singapore prefered coffee, a Western-preferred drink, or tea, an Eastern one.\n",
    "\n",
    "    sqlite > SELECT COUNT(*) \n",
    "             FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) AS tags\n",
    "             WHERE type = 'regular' AND key = 'name' AND tags.value LIKE '% coffee %';\n",
    "             \n",
    "    31\n",
    "    \n",
    "    sqlite > SELECT COUNT(*) \n",
    "             FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) AS tags\n",
    "             WHERE type = 'regular' AND key = 'name' AND tags.value LIKE '% tea %';\"\n",
    "             \n",
    "    24\n",
    "### Top Leisure Activities\n",
    "    sqlite > SELECT tags.value, COUNT(*) as count\n",
    "             FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) AS tags\n",
    "             WHERE key = 'leisure' GROUP BY tags.value\n",
    "             ORDER BY count DESC LIMIT 10;\n",
    "    \n",
    "    swimming_pool, 1271\n",
    "    pitch, 1056\n",
    "    park, 648\n",
    "    playground, 276\n",
    "    sports_centre, 110\n",
    "    park_connector, 83\n",
    "    fitness_centre, 76\n",
    "    golf_course, 51\n",
    "    garden, 48\n",
    "    recreation_ground', 48\n",
    "### Top Religions\n",
    "    sqlite > SELECT tags.value, COUNT(*) as count\n",
    "             FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) AS tags\n",
    "             WHERE key = 'religion' GROUP BY tags.value\n",
    "             ORDER BY count DESC LIMIT 10;\n",
    "    \n",
    "    muslim, 591\n",
    "    christian, 245\n",
    "    buddhist, 106\n",
    "    hindu, 23\n",
    "    taoist, 11\n",
    "    jewish, 4\n",
    "    sikh, 4\n",
    "    shinto, 1\n",
    "### Most Popular Foods\n",
    "    sqlite > SELECT tags.value, COUNT(*) as count\n",
    "             FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) AS tags\n",
    "             WHERE key = cuisine' GROUP BY tags.value\n",
    "             ORDER BY count DESC LIMIT 10;\n",
    "             \n",
    "    chinese, 170\n",
    "    burger, 96\n",
    "    japanese, 86\n",
    "    pizza, 64\n",
    "    coffee_shop, 57\n",
    "    chicken, 55\n",
    "    asian, 50\n",
    "    indian, 50\n",
    "    korean, 49\n",
    "    italian, 47"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Suggestions\n",
    "Much of the frustrations I had from cleaning the data came from the city names, with many incorrectly spelled major city names - not to mention house numbers, zipcodes, or random information about the location. I believe this was because users are made to input cities manually and are given no extra boxes to put notes on the location. If Open Street Maps had contibutors choose from a drop-down menu to input their city choice, with an 'other' option for extranous situations, much of the headache from inconsistant city naming across the board could be avoided. This would work extremely well if the user's current location is known, or he is inputting information for a major urban center.\n",
    "\n",
    "I was extremently interested in the 'leisure' tag, to find out what Singaporeans do for fun. Unfortunately, the majority of the data is unusable, with general values such as 'hotel' and 'attraction'. There's an opportunity there for more specific information to be presented.\n",
    "    \n",
    "        sqlite > SELECT tags.value, COUNT(*) \\\n",
    "                 FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) AS tags\n",
    "                 WHERE type = 'regular' and key = 'tourism' \n",
    "                 GROUP BY tags.value ORDER BY COUNT(*) DESC LIMIT 5;\n",
    "        \n",
    "        hotel, 563\n",
    "        attraction, 274\n",
    "        hostel, 82\n",
    "        information, 74\n",
    "        viewpoint, 59\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'muslim', 591)\n",
      "(u'christian', 245)\n",
      "(u'buddhist', 106)\n",
      "(u'hindu', 23)\n",
      "(u'taoist', 11)\n",
      "(u'jewish', 4)\n",
      "(u'sikh', 4)\n",
      "(u'shinto', 1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "sqlite3_filename = 'SingaporeMap2.db'\n",
    "connection = sqlite3.connect(sqlite3_filename)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "#Finds the streets with the most OSM objects connected to it.\n",
    "query = \"SELECT tags.value, COUNT(*) \\\n",
    "         FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) AS tags \\\n",
    "         WHERE type = 'addr' and key = 'street' \\\n",
    "         GROUP BY tags.value ORDER BY COUNT(*) DESC LIMIT 10;\"\n",
    "#Popular tourist venues\n",
    "queryA = \"SELECT tags.value, COUNT(*) FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) AS tags \\\n",
    "         WHERE type = 'regular' and key = 'tourism' GROUP BY tags.value ORDER BY COUNT(*) DESC;\"\n",
    "#coffee vs tea! - 131 tea, 124 coffee!\n",
    "queryB = \"SELECT COUNT(*) FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) AS tags \\\n",
    "         WHERE type = 'regular' AND key = 'name' AND tags.value LIKE '% coffee %';\"\n",
    "queryC = \"SELECT tags.value, COUNT(*) FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) AS tags \\\n",
    "         WHERE type = 'regular' AND key = 'name' AND tags.value LIKE '% tea %' \\\n",
    "         GROUP BY tags.value ORDER BY COUNT(*) DESC;\"\n",
    "#What are the most popular OSM 'objects' created by users? buildings and highways as it turns out\n",
    "query1 = \"SELECT tags.key, COUNT(*) FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) AS tags \\\n",
    "          WHERE type = 'regular' GROUP BY tags.key ORDER BY COUNT(*) DESC\"\n",
    "#most popular non-regular objects (addr, seamarks)\n",
    "query2 = \"SELECT tags.type, COUNT(*) FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) AS tags \\\n",
    "          GROUP BY tags.type ORDER BY COUNT(*) DESC\"\n",
    "#City name-likes in the data\n",
    "query3 = (\"SELECT tags.value, COUNT(*) as count \"\n",
    "          \"FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) tags \"\n",
    "          \"WHERE tags.key LIKE '%city%' \"\n",
    "          \"GROUP BY tags.value \"\n",
    "          \"ORDER BY count DESC \"\n",
    "          \"LIMIT 5;\")\n",
    "#All 'cuisines', 'leisure', 'religion'\n",
    "query5 = (\"SELECT tags.value, COUNT(*) as count \"\n",
    "          \"FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) AS tags \"\n",
    "          \"WHERE key = 'religion' GROUP BY tags.value \\\n",
    "          ORDER BY count DESC LIMIT 10;\"\n",
    ")\n",
    "#Use: \n",
    "query6 = (\"SELECT e.user, COUNT(*) as num FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e GROUP BY e.user ORDER BY num DESC LIMIT 10;\")\n",
    "for val, row in enumerate(cursor.execute(query5)):\n",
    "    #if val > 5:\n",
    "    #    break\n",
    "    #if (len(row[0]) < 6):\n",
    "    print row\n",
    "\n",
    "connection.close()\n",
    "\n",
    "#Ideas for data discovery\n",
    "# TEA vs COFFEE shops!\n",
    "#diverse religions, diverse cuisines, liesure activities, \n",
    "#Singapore is known as a meritocracy - heavy emphasis on education - school?, \n",
    "#Singapore's government is very dominant in all parts of Singapore - landuse?, military, \n",
    "#Singapore's Airport is considered the best in the world. Is there data for it? - aeroway? (get lat, lon -> )\n",
    "#Singapore prides itself a huge melting pot. Does it live up to that? - check religions and cuisines, denomination, place_of_worship\n",
    "# type='mtb' is mountain biking info, 'name' gives telugu/english names for things\n",
    "# type = regular, key = name, shop, foot[footpaths], bicycle, sport(most popular sports), tourism(make map w/ historic?), cuisine, religion, sac_scale(difficulty of hiking routes), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
