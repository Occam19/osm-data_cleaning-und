{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# OPENSTREETMAP CLEANING PROJECT\n",
    "## By: Gurpal Sandhu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This project is designed to show my data cleaning and exploration skills using SQL and python. [I took open-source data from OpenStreetMaps of the Singapore and the area around it](https://www.openstreetmap.org/search?query=singapore#map=11/1.2905/103.8520) to scrub and analyze. I am interested in visiting Singapore one day.\n",
    "\n",
    "The steps taken were:\n",
    "1. Check over the data. Done at first to find shape in python, later to find attribute data to answer questions with in SQL.\n",
    "2. Clean the data. Focused on cleaning addresses, in particular: street-end names, city names, and postcodes. Started by downloading and cleaning a small portion and then applying to main file. \n",
    "3. Convert the data into CSV from an XML formatted .OSM file. Then import into SQL db.\n",
    "4. Create questions about Singapore I would like to answer, and am able to answer using the data.\n",
    "5. Answer questions using SQL queries.\n",
    "6. Gave ideas for improvements to data, or alternate uses.\n",
    "\n",
    "## Data Cleaning\n",
    "\n",
    "The data downloaded from OpenStreetMaps is stored in an .osm file, size of 321 MB. An .osm file, as stated by the OpenStreetMaps wikipedia, uses the XML collapsible datastructure, along with a 'type:value' format to keep data tidy. I focused on cleaning the addresses of each node, since the address was what was input by hand by (fallible) human volunteers; in particular, the street-end names, city names, and postcodes.\n",
    "\n",
    "### Street-End Names\n",
    "\n",
    "A mapping was used to clean up the different end names. Since I had no awareness of typical Singaporean end names, I had to go back (after exploring with SQL) to include end-names like Lorong and Jalan alongside end-names like Street and Drive.\n",
    "\n",
    "    MAPPING = {\n",
    "        'Street':['str', 'st.', 'st'],\n",
    "        'Road':['rd', 'rd.'],\n",
    "        'Avenue':['ave', 'av', 'av.', 'ave.'],\n",
    "        'Jalan':['jl', 'jln', 'jl.'],\n",
    "        'Lane':['ln', 'ln.'],\n",
    "        'Drive':['dr', 'dr.'],\n",
    "        'Lorong':['lr', 'lr.'],\n",
    "        'Square':['sq', 'sq.']\n",
    "    }\n",
    "### Postcodes\n",
    "\n",
    "Postcodes in Singapore are a 6 number string with the first two numbers the general area, and the last four the exact location. Some online research showed me that the 81 postcode area is the newest postal sector, and in my SQL queries, I noticed that it had many of the bad post codes. The steps used to clean the codes were:\n",
    "1. Remove all non-numbers. Done using regex (regular expressions module in python).\n",
    "\n",
    "        newstring = re.sub('[^0-9]','', string)\n",
    "\n",
    "2. Add 0 in front of 9---- 5 length numbers (there are no codes that start with 9 in Singapore)\n",
    "3. Add 0 to end of numbers with 2 00s on end that are 5 length numbers (these are estimations)\n",
    "4. Rest are removed, replaced with ''.\n",
    "\n",
    "### City Names\n",
    "\n",
    "Oftentimes, extra information would be put here instead of or alongside the cityname.\n",
    "First, any city names with any numbers in the string AND with fewer letters than 3 were automatically deleted. Regex was used here.\n",
    "Then, a mapping was used to fix the rest of the city names. The majority of names are the 5 big ones:\n",
    "\n",
    "    CITYNAMES = {\"singap\" : \"Singapore\",           # singap to encompass all spellings of singap - ur, or, ore, our\n",
    "                 \"johor bahru\" : \"Johor Bahru\",    # written in order of size to choose most likely city for multiple named city\n",
    "                 \"pasir gudang\" : \"Pasir Gudang\", \n",
    "                 \"batam\" : \"Batam\", \n",
    "                 \"skudai\" : \"Skudai\"}\n",
    "There were many variations in the data for city names(ie. Singapore/singapur). As a result, if it had 'singap', 'bahru', 'pasir', 'batam', 'skudai' anywhere in the string, it was changed to align. Finally, the first letter was changed to uppercase - for any city name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Importing / SQL Overview\n",
    "\n",
    "The map data was extracted from an XML format, and changed from XML to python's dict structure. Then, the values were audited and cleaned as shown above. The data was separated into 5 csv files, and finally imported into SQL under the same headers.  I also tried importing directly from the command line, but the encoding was finicky. The CSV / SQL column names are below.\n",
    "\n",
    "    NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "    NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "    WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "    WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "    WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "### File Sizes\n",
    "Singapore.osm - 321 MB\n",
    "nodes, nodes_tags, ways, ways_nodes, ways_tags . csv - 201 MB\n",
    "SingaporeMap.db - 182 MB\n",
    "\n",
    "### Node and Ways Count\n",
    "\n",
    "    sqlite> SELECT COUNT(*) FROM nodes;\n",
    "\n",
    "    Nodes : 1482437\n",
    "\n",
    "    sqlite> SELECT COUNT(*) FROM ways;\n",
    "    \n",
    "    Ways : 233033\n",
    "### Unique Contributor Data\n",
    "\n",
    "    sqlite > SELECT COUNT(DISTINCT(tags.uid))\n",
    "             FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) AS tags;\n",
    "             \n",
    "    Total Contributor Count : 2057\n",
    "\n",
    "    sqlite > SELECT tags.user, COUNT(*) as num\n",
    "             FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) AS tags\n",
    "             GROUP BY tags.user ORDER BY num DESC\n",
    "             LIMIT 5;\n",
    "             \n",
    "    Top 5 Contributors:\n",
    "        JaLooNz, 395146\n",
    "        berjaya, 117636\n",
    "        rene78, 78269\n",
    "        cboothroyd, 73129\n",
    "        lmum, 44070"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answering Questions about Singapore\n",
    "### Major Streets\n",
    "I wanted to know what the major streets of Singapore were. I looked for streets with the most OSM objects connected to it.\n",
    "        \n",
    "    sqlite > SELECT tags.value, COUNT(*) \n",
    "             FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) AS tags \n",
    "             WHERE type = 'addr' and key = 'street' \n",
    "             GROUP BY tags.value ORDER BY COUNT(*) DESC LIMIT 10;\n",
    "      \n",
    "    Joo Chiat Road, 347\n",
    "    Geylang Road, 261\n",
    "    Serangoon Road, 246\n",
    "    Jalan Senang, 234\n",
    "    South Bridge Road, 197\n",
    "    Jalan Besar, 192\n",
    "    North Bridge Road, 188\n",
    "    Tanjong Pagar Road, 181\n",
    "    Arab Street, 168\n",
    "    Westwood Crescent, 165\n",
    "### Tea vs Coffee Preference\n",
    "Another question I had was whether a highly developed Eastern city like Singapore prefered coffee, a Western-preferred drink, or tea, an Eastern one.\n",
    "\n",
    "    sqlite > SELECT COUNT(*) \n",
    "             FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) AS tags\n",
    "             WHERE type = 'regular' AND key = 'name' AND tags.value LIKE '% coffee %';\n",
    "             \n",
    "    31\n",
    "    \n",
    "    sqlite > SELECT COUNT(*) \n",
    "             FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) AS tags\n",
    "             WHERE type = 'regular' AND key = 'name' AND tags.value LIKE '% tea %';\"\n",
    "             \n",
    "    24\n",
    "### Top Leisure Activities\n",
    "    sqlite > SELECT tags.value, COUNT(*) as count\n",
    "             FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) AS tags\n",
    "             WHERE key = 'leisure' GROUP BY tags.value\n",
    "             ORDER BY count DESC LIMIT 10;\n",
    "    \n",
    "    swimming_pool, 1271\n",
    "    pitch, 1056\n",
    "    park, 648\n",
    "    playground, 276\n",
    "    sports_centre, 110\n",
    "    park_connector, 83\n",
    "    fitness_centre, 76\n",
    "    golf_course, 51\n",
    "    garden, 48\n",
    "    recreation_ground', 48\n",
    "### Top Religions\n",
    "    sqlite > SELECT tags.value, COUNT(*) as count\n",
    "             FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) AS tags\n",
    "             WHERE key = 'religion' GROUP BY tags.value\n",
    "             ORDER BY count DESC LIMIT 10;\n",
    "    \n",
    "    muslim, 591\n",
    "    christian, 245\n",
    "    buddhist, 106\n",
    "    hindu, 23\n",
    "    taoist, 11\n",
    "    jewish, 4\n",
    "    sikh, 4\n",
    "    shinto, 1\n",
    "### Most Popular Foods\n",
    "    sqlite > SELECT tags.value, COUNT(*) as count\n",
    "             FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) AS tags\n",
    "             WHERE key = cuisine' GROUP BY tags.value\n",
    "             ORDER BY count DESC LIMIT 10;\n",
    "             \n",
    "    chinese, 170\n",
    "    burger, 96\n",
    "    japanese, 86\n",
    "    pizza, 64\n",
    "    coffee_shop, 57\n",
    "    chicken, 55\n",
    "    asian, 50\n",
    "    indian, 50\n",
    "    korean, 49\n",
    "    italian, 47"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Suggestions\n",
    "Much of the frustrations I had from cleaning the data came from the city names, with many incorrectly spelled major city names - not to mention house numbers, zipcodes, or random information about the location. I believe this was because users are made to input cities manually and are given no extra boxes to put notes on the location. If Open Street Maps had contibutors choose from a drop-down menu to input their city choice, with an 'other' option for extranous situations, much of the headache from inconsistant city naming across the board could be avoided. This would work extremely well if the user's current location is known, or he is inputting information for a major urban center.\n",
    "\n",
    "I was extremently interested in the 'leisure' tag, to find out what Singaporeans do for fun. Unfortunately, the majority of the data is unusable, with general values such as 'hotel' and 'attraction'. There's an opportunity there for more specific information to be presented.\n",
    "    \n",
    "        sqlite > SELECT tags.value, COUNT(*) \\\n",
    "                 FROM (SELECT * FROM nodes_tags UNION ALL SELECT * FROM ways_tags) AS tags\n",
    "                 WHERE type = 'regular' and key = 'tourism' \n",
    "                 GROUP BY tags.value ORDER BY COUNT(*) DESC LIMIT 5;\n",
    "        \n",
    "        hotel, 563\n",
    "        attraction, 274\n",
    "        hostel, 82\n",
    "        information, 74\n",
    "        viewpoint, 59\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusion\n",
    "I have a firmer grasp on good data cleaning habits after this project, with a better sense of the large trial-retrial aspect of auditing. Additionally, I learned alot about Singapore from analyzing the street data, solidifying my wish to travel there one day.\n",
    "\n",
    "References:\n",
    "1. https://docs.python.org/3/library\n",
    "2. https://wiki.openstreetmap.org/wiki/Main_Page\n",
    "3. https://discussions.udacity.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
