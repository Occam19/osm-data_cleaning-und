{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "######################\n",
    "### CLEANING DATA  ###\n",
    "######################\n",
    "\n",
    "import re\n",
    "\n",
    "def audit_postcode (string):\n",
    "    #remove all non-numbers\n",
    "    newstring = re.sub('[^0-9]','', string)\n",
    "    if len(newstring) == 6:\n",
    "        return newstring\n",
    "    #add 0 in front of 9---- 5 length numbers (there are no codes that start with 9 in singapore, miust be 6 numbers)\n",
    "    #add 0 to end of numbers with 2 00s on end that are 5 length numbers (these are estimates)\n",
    "    if len(newstring) == 5:\n",
    "        if newstring[0] == '9':\n",
    "            newstring2 = '0' + newstring\n",
    "            print 'ERROR POSTCODE: ' + newstring + ' -> ' + newstring2\n",
    "            return newstring2\n",
    "        if newstring[-2:] == '00':\n",
    "            newstring3 = newstring + '0'\n",
    "            print 'ERROR POSTCODE: ' + newstring + ' -> ' + newstring3\n",
    "            return newstring3\n",
    "    return 'BADCODE'\n",
    "    \n",
    "#city names - Singapore, Johor Bahru, Pasir Gudang, Batam, Skudai\n",
    "CITYNAMES = {\"singap\" : \"Singapore\",           # singap to encompass all spellings of singap - ur, or, ore, our\n",
    "             \"johor\" : \"Johor Bahru\",    # written in order of size to choose most likely city for multiple named city\n",
    "             \"pasir\" : \"Pasir Gudang\", \n",
    "             \"batam\" : \"Batam\", \n",
    "             \"skudai\" : \"Skudai\"}\n",
    "\n",
    "def audit_cityname (string, citynames = CITYNAMES):\n",
    "    string = string.lower()\n",
    "    for name in citynames.keys():\n",
    "        if name in string:\n",
    "            return citynames[name]\n",
    "    #REMOVE any entries that have numberss in them AND has less than 3 letters in string\n",
    "    if re.search('^#[\\d]{2}-[\\d]{2}', string):\n",
    "            print 'ERROR CITY: ' + string + ' -> ADDR:UNIT'\n",
    "            return 'unit: ' + string \n",
    "    if bool(re.search(r'\\d', string)) and bool(sum(c.isalpha() for c in string) < 2):\n",
    "        print 'ERROR CITY: ' + string + ' -> BADSTRING'\n",
    "        return 'BADSTRING'\n",
    "    return string.title()  # capitalize any other city names\n",
    "    \n",
    "#Make street names consistent with Rd. -> Road, Ave -> Avenu\n",
    "MAPPING = {\n",
    "    'Street':['str', 'st.', 'st'],\n",
    "    'Road':['rd', 'rd.'],\n",
    "    'Avenue':['ave', 'av', 'av.', 'ave.'],\n",
    "    'Jalan':['jl', 'jln', 'jl.'],\n",
    "    'Lane':['ln', 'ln.'],\n",
    "    'Drive':['dr', 'dr.'],\n",
    "    'Lorong':['lr', 'lr.'],\n",
    "    'Square':['sq', 'sq.']\n",
    "}\n",
    "\n",
    "#audit_streetname helper function, compares each word to mapping dictionary\n",
    "def check_word_for_streettype (string, dictionary):\n",
    "    for streettype, mapping in dictionary.items():\n",
    "        for abbreviation in mapping:\n",
    "            if string == abbreviation:\n",
    "                print 'ERROR STREETNAME: ' + string + ' -> ' + streettype\n",
    "                return streettype\n",
    "    return string\n",
    "\n",
    "#split string on space AND '.', for each word -> strip spaces:\n",
    "def audit_streetname (string):\n",
    "    audited_addr = ''\n",
    "    temp_string = string.strip().lower().split()\n",
    "    for part in temp_string:\n",
    "        audited_part = check_word_for_streettype(part, MAPPING)\n",
    "        audited_addr += audited_part.title() + ' '\n",
    "    return audited_addr[:-1]\n",
    "\n",
    "def audit_value(value, address_part):\n",
    "    if address_part == 'postcode':\n",
    "        return audit_postcode(value)\n",
    "    elif address_part == 'city':\n",
    "        return audit_cityname(value)\n",
    "    elif address_part == 'street':\n",
    "        return audit_streetname(value)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "##################\n",
    "### XML TO CSV ###\n",
    "##################\n",
    "\n",
    "import csv\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "OSM_PATH = \"singapore.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "# Convert XML file structure to python dict structure\n",
    "def extract_tag_info(element, problem_chars=PROBLEMCHARS):\n",
    "    tags = []   # Handle secondary tags the same way for both node and way elements\n",
    "    for tag in element.findall('tag'):\n",
    "        tag_info = {}\n",
    "        tag_info['id'] = element.attrib['id']\n",
    "        tag_info['value'] = tag.attrib['v']\n",
    "        if problem_chars.match(tag.attrib['k']):\n",
    "            continue\n",
    "        elif ':' not in tag.attrib['k']:\n",
    "            tag_info['key'] = tag.attrib['k']\n",
    "            tag_info['type'] = 'regular'\n",
    "        else:\n",
    "            (tag_info['type'],c,tag_info['key']) = tag.attrib['k'].partition(':')\n",
    "            if tag_info['type'] == 'addr':\n",
    "                tag_info['value'] = audit_value(tag_info['value'], tag_info['key'])\n",
    "                if tag_info['value'] == 'BADSTRING':\n",
    "                    continue\n",
    "                if tag_info['value'] == 'addr:unit':\n",
    "                    tag_info['key'] = 'unit'\n",
    "                    tag_info['value'] = tag.attrib['v']\n",
    "        tags.append(tag_info)\n",
    "    return tags\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    \n",
    "    if element.tag == 'node':\n",
    "        for key in node_attr_fields:\n",
    "            node_attribs[key] = element.attrib[key]\n",
    "        tags = extract_tag_info(element)\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        for key in way_attr_fields:\n",
    "            way_attribs[key] = element.attrib[key]\n",
    "        tags = extract_tag_info(element)\n",
    "        for position, nd in enumerate(element.findall('nd')):\n",
    "            way_node_info = {}\n",
    "            way_node_info['id'] = element.attrib['id']\n",
    "            way_node_info['node_id'] = nd.attrib['ref']\n",
    "            way_node_info['position'] = position\n",
    "            way_nodes.append(way_node_info)\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "# Helper Functions\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# Main Function\n",
    "def process_map(file_in):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "process_map(OSM_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#####################\n",
    "### CSV TO SQL DB ###\n",
    "#####################\n",
    "\n",
    "import csv\n",
    "import sqlite3\n",
    "from collections import OrderedDict\n",
    "\n",
    "##function to import any csv file to sqlite3 db, columns_vartype is an OrderedDict with line data\n",
    "def import_csv(tablename, columns_vartype, filename):\n",
    "\n",
    "    cursor.execute('''DROP TABLE IF EXISTS {}'''.format(tablename))\n",
    "    connection.commit()\n",
    "\n",
    "    # creates strings for CREATE TABLE and INSERT INTO queries of multiple variable amounts\n",
    "    query1 = ('''CREATE TABLE %s (''' % tablename)\n",
    "    query2 = (\"INSERT INTO %s(\" % tablename)\n",
    "    subquery = \"(\"\n",
    "    for val in columns_vartype.keys():\n",
    "        query1 += ('''%s %s NOT NULL''' % (val, columns_vartype[val]))\n",
    "        if val == columns_vartype.keys()[-1]:\n",
    "            query1 += (\");\")\n",
    "            query2 += (\"%s) VALUES \" % val)\n",
    "            subquery += \"?);\"\n",
    "        else:\n",
    "            query1 += (\", \")\n",
    "            query2 += (\"%s, \" % val)\n",
    "            subquery += \"?, \"\n",
    "    query2 += subquery        \n",
    "    \n",
    "    cursor.execute(query1)\n",
    "    connection.commit()\n",
    "\n",
    "    \n",
    "    with open(filename) as fin:\n",
    "        data = csv.DictReader(fin)\n",
    "        create_db = []\n",
    "        for row in data:\n",
    "            temp_db = []\n",
    "            for value in columns_vartype.keys():\n",
    "                temp_db.append(row[value].decode(\"utf-8\"))\n",
    "            create_db.append(temp_db)\n",
    "              \n",
    "    cursor.executemany(query2, create_db)\n",
    "    connection.commit()\n",
    "    \n",
    "## Import data into SQLITE database, using same CSV columns as above\n",
    "sqlite3_filename = 'SingaporeMap2.db'\n",
    "connection = sqlite3.connect(sqlite3_filename)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "Nodes_Dictionary = OrderedDict([('id', 'INTEGER'), ('lat', 'REAL'), ('lon', 'REAL'), ('user', 'TEXT'), \n",
    "                                ('uid', 'INTEGER'), ('version', 'INTEGER'), ('changeset', 'INTEGER'), ('timestamp', 'TEXT')])\n",
    "Nodes_Tags_Dictionary = OrderedDict([('id', 'INTEGER'), ('key', 'TEXT'), ('value', 'TEXT'), ('type', 'TEXT')])\n",
    "Ways_Dictionary = OrderedDict([('id', 'INTEGER'), ('user', 'TEXT'), ('uid', 'INTEGER'), ('version', 'INTEGER'), \n",
    "                               ('changeset', 'INTEGER'), ('timestamp', 'TEXT')])\n",
    "Ways_Nodes_Dictionary = OrderedDict([('id', 'INTEGER'), ('node_id', 'INTEGER'), ('position', 'INTEGER')])\n",
    "Ways_Tags_Dictionary = OrderedDict([('id', 'INTEGER'), ('key', 'TEXT'), ('value', 'TEXT'), ('type', 'TEXT')])\n",
    "\n",
    "import_csv('Nodes_Tags', Nodes_Tags_Dictionary, 'nodes_tags.csv')\n",
    "import_csv('Nodes', Nodes_Dictionary, 'nodes.csv')\n",
    "import_csv('Ways', Ways_Dictionary, 'ways.csv')\n",
    "import_csv('Ways_Nodes', Ways_Nodes_Dictionary, 'ways_nodes.csv')\n",
    "import_csv('Ways_Tags', Ways_Tags_Dictionary, 'ways_tags.csv')\n",
    "\n",
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
